{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import save_model\n",
    "from keras.models import save_weights\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeAdversarialNetwork():\n",
    "    def __init__(self, path_to_input, input_mask, input_shape, latent_space):\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_space = latent_space\n",
    "        self.data = self.load_data(path_to_input, input_mask)\n",
    "        # Configure our component and composite models\n",
    "        self.generator = self.configure_generator()\n",
    "        self.discriminator = self.configure_discriminator()\n",
    "        self.model = self.configure_generative_adversarial_network()\n",
    "\n",
    "    def load_data(self, path_to_input, input_mask):\n",
    "        files = os.listdir(path_to_input)\n",
    "        # Applying input mask to list of files in directory\n",
    "        for file in files:\n",
    "            if file[-3] != input_mask:\n",
    "                files.remove(file)\n",
    "        # Declaring dataset\n",
    "        data = np.zeros((len(files), self.input_shape[0], self.input_shape[1], self.input_shape[2]))\n",
    "        i = 0\n",
    "        # Loading dataset\n",
    "        for file in files:\n",
    "            data[i, :, :, :] = read(file)\n",
    "            i += 1\n",
    "        # Preprocessing (Normalisation) dataset\n",
    "        data = data.astype('float32')\n",
    "        data = data / 255.0\n",
    "        return data\n",
    "    \n",
    "    def export(self, path_to_output):\n",
    "        save_model(\n",
    "            model=self.generator,\n",
    "            filepath=path_to_output,\n",
    "            overwrite=True,\n",
    "            include_optimizer=True,\n",
    "            save_format='tf',\n",
    "            signatures=None,\n",
    "            options=None\n",
    "        )\n",
    "        save_weights(\n",
    "            model=self.generator,\n",
    "            filepath=path_to_output,\n",
    "            overwrite=True,\n",
    "            save_format='tf',\n",
    "            options=None\n",
    "        )\n",
    "\n",
    "    def configure_generator(self, num_variation=128):\n",
    "        model = Sequential()\n",
    "        # Input Layer / 25% nodes downsample\n",
    "        num_nodes = num_variation * self.input_shape[0] * self.input_shape[1] * 0.25 * 0.25 * self.input_shape[2]\n",
    "        num_nodes = int(num_nodes)\n",
    "        model.add(Dense(num_nodes, input_dim=self.latent_space))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Reshape(int(self.input_shape[0] * 0.25), int(self.input_shape[1] * 0.25), self.input_shape[2], num_variation))\n",
    "        # Hidden Layer 1 / 50% nodes upsample\n",
    "        model.add(Conv2DTranspose(num_variation, kernel_size=4, strides=(2, 2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        # Hidden Layer 2 / 100% nodes upsample\n",
    "        model.add(Conv2DTranspose(num_variation, kernel_size=4, strides=(2, 2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        # Output Layer\n",
    "        model.add(Conv2D(self.input_shape[2], kernel_size=(int(self.input_shape[0] * 0.25), int(self.input_shape[1] * 0.25)), activation='sigmoid', padding='same'))\n",
    "        display(model.summary())\n",
    "        return model\n",
    "\n",
    "    def configure_discriminator(self):\n",
    "        model = Sequential()\n",
    "        # Hidden Layer 1 / 64 nodes / 3 * 3 * 3 kernel / 2 * 2 strides\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=(2, 2), padding='same', input_shape=self.input_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        # Hidden Layer 2 / 64 nodes / 3 * 3 * 3 kernel / 2 * 2 strides\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=(2, 2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        # Preprocessing\n",
    "        model.add(Flatten())\n",
    "        # Output Layer / 1 node / sigmoid activation\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        # Compile Neural Network\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy', 'precision', 'recall'])\n",
    "        display(model.summary())\n",
    "        return model\n",
    "\n",
    "    def configure_generative_adversarial_network(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential()\n",
    "        # Generator\n",
    "        model.add(self.generator)\n",
    "        # Discriminator\n",
    "        model.add(self.discriminator)\n",
    "        # Compile Generative Adversarial Network\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "        display(model.summary())\n",
    "        return model\n",
    "    \n",
    "    def sample_latent_points(self, num_sample):\n",
    "        data = randn(self.latent_space * num_sample)\n",
    "        data = data.reshape(num_sample, self.latent_space)\n",
    "        return data\n",
    "        \n",
    "    def sample_truth(self, num_sample=128):\n",
    "        observations = randint(0, self.data.shape[0], num_sample)\n",
    "        data = self.data[observations]\n",
    "        target = ones((num_sample, 1))\n",
    "        return data, target\n",
    "    \n",
    "    def sample_false(self, num_sample=128):\n",
    "        data = self.sample_latent_points(num_sample)\n",
    "        data = self.generator.predict(data)\n",
    "        target = zeros((num_sample, 1))\n",
    "        return data, target\n",
    "    \n",
    "    def train(self, num_epoch=100, num_batch=256):\n",
    "        for i in range(num_epoch):\n",
    "            for j in range(int(self.data.shape[0] / num_batch)):\n",
    "                data_truth, target_truth = self.sample_truth(self.data, int(num_batch * 0.5))\n",
    "                data_false, target_false = self.sample_false(self.data, int(num_batch * 0.5))\n",
    "                data, target = vstack((data_truth, data_false)), vstack((target_truth, target_false))\n",
    "                discriminator_loss, _ = self.discriminator.train_on_batch(data, target)\n",
    "\n",
    "                data = self.sample_latent_points(num_batch)\n",
    "                target = ones((num_batch, 1))\n",
    "                generator_loss = self.model.train_on_batch(data, target)\n",
    "\n",
    "                print(\"Epoch [{}]: Batch [{} / {}] / Discriminator Loss={}%, Generator Loss={}%\".format(i+1, j+1, int(self.data.shape[0] / num_batch), discriminator_loss, generator_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    SAN_GAN = GenerativeAdversarialNetwork('~/Desktop/SAN-GAN/training-image-data', '.JPG', (500, 500, 3), 100)\n",
    "    SAN_GAN.train()\n",
    "    SAN_GAN.export('~/Desktop/SAN-GAN/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
